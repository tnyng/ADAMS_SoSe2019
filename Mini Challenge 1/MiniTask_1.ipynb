{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniTask 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YmWiiSkVVFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "from scipy.stats import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUB9ZcCEH-Ep",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6AnHi8RZlH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "condata = pd.read_csv(\"https://raw.githubusercontent.com/tnyng/ADAMS_SS19/master/ConversionDataSet.csv\")\n",
        "condata = condata.drop('Unnamed: 0', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2iBcSKAgpL-",
        "colab_type": "code",
        "outputId": "26dabc84-f2e8-419f-ad34-ee7963c59d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Have a overview of the dataset\n",
        "condata.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>Kauf</th>\n",
              "      <th>sessionStartHour</th>\n",
              "      <th>dayOfMonth</th>\n",
              "      <th>weekday</th>\n",
              "      <th>sessionTime</th>\n",
              "      <th>category</th>\n",
              "      <th>pageVisitedBeforeSession</th>\n",
              "      <th>amountBasketSession</th>\n",
              "      <th>totalItemValueBasketSession</th>\n",
              "      <th>sessionProduct</th>\n",
              "      <th>sessionSearch</th>\n",
              "      <th>sessionOverview</th>\n",
              "      <th>sessionSale</th>\n",
              "      <th>sessionCart</th>\n",
              "      <th>percPageProduct</th>\n",
              "      <th>percPageSearch</th>\n",
              "      <th>percPageOverview</th>\n",
              "      <th>percPageSale</th>\n",
              "      <th>percPageCart</th>\n",
              "      <th>countPagesRevisited</th>\n",
              "      <th>timeOnPage</th>\n",
              "      <th>checkoutStep</th>\n",
              "      <th>clickEventsSession</th>\n",
              "      <th>scrollEventSession</th>\n",
              "      <th>tabSwitchSession</th>\n",
              "      <th>clickEventProduct</th>\n",
              "      <th>scrollEventProduct</th>\n",
              "      <th>tabSwitchProduct</th>\n",
              "      <th>clickEventSearch</th>\n",
              "      <th>scrollEventSearch</th>\n",
              "      <th>tabSwitchSearch</th>\n",
              "      <th>clickEventOverview</th>\n",
              "      <th>scrollEventOverview</th>\n",
              "      <th>tabSwitchOverview</th>\n",
              "      <th>clickEventSale</th>\n",
              "      <th>scrollEventSale</th>\n",
              "      <th>tabswitchSale</th>\n",
              "      <th>clickEventCart</th>\n",
              "      <th>scrollEventCart</th>\n",
              "      <th>...</th>\n",
              "      <th>recencyVisit</th>\n",
              "      <th>countPagesRevisitedLastSession</th>\n",
              "      <th>currentPageVisitedLastTime</th>\n",
              "      <th>frequencyVisit</th>\n",
              "      <th>totViewCount</th>\n",
              "      <th>totVisitTime</th>\n",
              "      <th>totPurchasesAmount</th>\n",
              "      <th>totPurchasesItems</th>\n",
              "      <th>totProduct</th>\n",
              "      <th>totSearch</th>\n",
              "      <th>totOverview</th>\n",
              "      <th>totSale</th>\n",
              "      <th>totCart</th>\n",
              "      <th>totPercPageOverview</th>\n",
              "      <th>totPercPageProduct</th>\n",
              "      <th>totPercPageSearch</th>\n",
              "      <th>totPercPageSale</th>\n",
              "      <th>totPercPageCart</th>\n",
              "      <th>convertedBefore</th>\n",
              "      <th>hurry</th>\n",
              "      <th>currentViewCountVsPreviousAvg</th>\n",
              "      <th>currentVisitLengthVsAvg</th>\n",
              "      <th>meanRecencyVisit</th>\n",
              "      <th>pageProductrVisit</th>\n",
              "      <th>pageSearchrVisit</th>\n",
              "      <th>pageOverviewrVisit</th>\n",
              "      <th>pageSalerVisit</th>\n",
              "      <th>pageCartrVisit</th>\n",
              "      <th>purchasesrVisit</th>\n",
              "      <th>browser</th>\n",
              "      <th>browserVersion</th>\n",
              "      <th>operatingSystem</th>\n",
              "      <th>operatingSystemVersion</th>\n",
              "      <th>majorCity</th>\n",
              "      <th>screenWidth</th>\n",
              "      <th>screenHeight</th>\n",
              "      <th>windowWidth</th>\n",
              "      <th>windowHeight</th>\n",
              "      <th>tabVisible</th>\n",
              "      <th>visitorKnown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>overview</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>IE</td>\n",
              "      <td>1</td>\n",
              "      <td>Windows 7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1280</td>\n",
              "      <td>1024</td>\n",
              "      <td>1280</td>\n",
              "      <td>844</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>85</td>\n",
              "      <td>search</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.112741</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Firefox</td>\n",
              "      <td>2</td>\n",
              "      <td>Windows 8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1366</td>\n",
              "      <td>768</td>\n",
              "      <td>1339</td>\n",
              "      <td>634</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>overview</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Chrome</td>\n",
              "      <td>2</td>\n",
              "      <td>Windows 8.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1600</td>\n",
              "      <td>900</td>\n",
              "      <td>1600</td>\n",
              "      <td>799</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>162</td>\n",
              "      <td>overview</td>\n",
              "      <td>1</td>\n",
              "      <td>9.95</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.045554</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Firefox</td>\n",
              "      <td>2</td>\n",
              "      <td>Windows 7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1280</td>\n",
              "      <td>1024</td>\n",
              "      <td>1280</td>\n",
              "      <td>891</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>52</td>\n",
              "      <td>product</td>\n",
              "      <td>0</td>\n",
              "      <td>39.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Chrome</td>\n",
              "      <td>2</td>\n",
              "      <td>Windows 7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1600</td>\n",
              "      <td>900</td>\n",
              "      <td>1600</td>\n",
              "      <td>775</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   month  Kauf  sessionStartHour  ...  windowHeight  tabVisible  visitorKnown\n",
              "0      8     0                21  ...           844           1             0\n",
              "1      8     0                 0  ...           634           1             1\n",
              "2      8     0                10  ...           799           1             1\n",
              "3      8     0                 8  ...           891           1             1\n",
              "4      8     0                17  ...           775           1             1\n",
              "\n",
              "[5 rows x 96 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Lgk0sbJ4Yl",
        "colab_type": "code",
        "outputId": "6d0a20b0-4607-4561-abd1-6b8ed1995a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "condata.shape "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51349, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jacqvENkKkXV",
        "colab_type": "text"
      },
      "source": [
        "#### There are 51349 observations, i.e. clients and 96 features, i.e. information or activities of the clients, where \"Kauf\" is regarded as the target variable. However, we still need to check whether the dataset is balanced, that is, whether the two classes of the target variable are equally distributed. An imbalanced data structure might lead to an illegal result (high prediction accuracy) in the end, because the model will focus mainly on the majority class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_LarrB6bGzC",
        "colab_type": "code",
        "outputId": "5102986c-b4a8-4d1f-b263-19928e9786c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "class_counts = condata.groupby('Kauf').size()\n",
        "print(class_counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kauf\n",
            "0    47237\n",
            "1     4112\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuk1Ws0Rcty_",
        "colab_type": "text"
      },
      "source": [
        "#### As we could see, the dataset is imbalanced. Whereas there are 47237 observations in the positive class, i.e. clients who did not convert to purchase, only 4112 are in the negative class, which means only a small portion of the clients actually converted to purchase. \n",
        "#### In the next step, we then transform some of our feature types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5dqlvaMlb-Z",
        "colab_type": "code",
        "outputId": "6be0414d-7dc9-4c73-c8d8-f218fb6c5cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Transform the categorical features into numeric data types\n",
        "encoder = LabelEncoder()\n",
        "condata[\"category\"] = encoder.fit_transform(condata[\"category\"])\n",
        "condata[\"browser\"] = encoder.fit_transform(condata[\"browser\"])\n",
        "condata[\"operatingSystem\"] = encoder.fit_transform(condata[\"operatingSystem\"])\n",
        "condata.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>Kauf</th>\n",
              "      <th>sessionStartHour</th>\n",
              "      <th>dayOfMonth</th>\n",
              "      <th>weekday</th>\n",
              "      <th>sessionTime</th>\n",
              "      <th>category</th>\n",
              "      <th>pageVisitedBeforeSession</th>\n",
              "      <th>amountBasketSession</th>\n",
              "      <th>totalItemValueBasketSession</th>\n",
              "      <th>sessionProduct</th>\n",
              "      <th>sessionSearch</th>\n",
              "      <th>sessionOverview</th>\n",
              "      <th>sessionSale</th>\n",
              "      <th>sessionCart</th>\n",
              "      <th>percPageProduct</th>\n",
              "      <th>percPageSearch</th>\n",
              "      <th>percPageOverview</th>\n",
              "      <th>percPageSale</th>\n",
              "      <th>percPageCart</th>\n",
              "      <th>countPagesRevisited</th>\n",
              "      <th>timeOnPage</th>\n",
              "      <th>checkoutStep</th>\n",
              "      <th>clickEventsSession</th>\n",
              "      <th>scrollEventSession</th>\n",
              "      <th>tabSwitchSession</th>\n",
              "      <th>clickEventProduct</th>\n",
              "      <th>scrollEventProduct</th>\n",
              "      <th>tabSwitchProduct</th>\n",
              "      <th>clickEventSearch</th>\n",
              "      <th>scrollEventSearch</th>\n",
              "      <th>tabSwitchSearch</th>\n",
              "      <th>clickEventOverview</th>\n",
              "      <th>scrollEventOverview</th>\n",
              "      <th>tabSwitchOverview</th>\n",
              "      <th>clickEventSale</th>\n",
              "      <th>scrollEventSale</th>\n",
              "      <th>tabswitchSale</th>\n",
              "      <th>clickEventCart</th>\n",
              "      <th>scrollEventCart</th>\n",
              "      <th>...</th>\n",
              "      <th>recencyVisit</th>\n",
              "      <th>countPagesRevisitedLastSession</th>\n",
              "      <th>currentPageVisitedLastTime</th>\n",
              "      <th>frequencyVisit</th>\n",
              "      <th>totViewCount</th>\n",
              "      <th>totVisitTime</th>\n",
              "      <th>totPurchasesAmount</th>\n",
              "      <th>totPurchasesItems</th>\n",
              "      <th>totProduct</th>\n",
              "      <th>totSearch</th>\n",
              "      <th>totOverview</th>\n",
              "      <th>totSale</th>\n",
              "      <th>totCart</th>\n",
              "      <th>totPercPageOverview</th>\n",
              "      <th>totPercPageProduct</th>\n",
              "      <th>totPercPageSearch</th>\n",
              "      <th>totPercPageSale</th>\n",
              "      <th>totPercPageCart</th>\n",
              "      <th>convertedBefore</th>\n",
              "      <th>hurry</th>\n",
              "      <th>currentViewCountVsPreviousAvg</th>\n",
              "      <th>currentVisitLengthVsAvg</th>\n",
              "      <th>meanRecencyVisit</th>\n",
              "      <th>pageProductrVisit</th>\n",
              "      <th>pageSearchrVisit</th>\n",
              "      <th>pageOverviewrVisit</th>\n",
              "      <th>pageSalerVisit</th>\n",
              "      <th>pageCartrVisit</th>\n",
              "      <th>purchasesrVisit</th>\n",
              "      <th>browser</th>\n",
              "      <th>browserVersion</th>\n",
              "      <th>operatingSystem</th>\n",
              "      <th>operatingSystemVersion</th>\n",
              "      <th>majorCity</th>\n",
              "      <th>screenWidth</th>\n",
              "      <th>screenHeight</th>\n",
              "      <th>windowWidth</th>\n",
              "      <th>windowHeight</th>\n",
              "      <th>tabVisible</th>\n",
              "      <th>visitorKnown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1280</td>\n",
              "      <td>1024</td>\n",
              "      <td>1280</td>\n",
              "      <td>844</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>85</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.112741</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1366</td>\n",
              "      <td>768</td>\n",
              "      <td>1339</td>\n",
              "      <td>634</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1600</td>\n",
              "      <td>900</td>\n",
              "      <td>1600</td>\n",
              "      <td>799</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>162</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>9.95</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.045554</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1280</td>\n",
              "      <td>1024</td>\n",
              "      <td>1280</td>\n",
              "      <td>891</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>52</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>39.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1600</td>\n",
              "      <td>900</td>\n",
              "      <td>1600</td>\n",
              "      <td>775</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   month  Kauf  sessionStartHour  ...  windowHeight  tabVisible  visitorKnown\n",
              "0      8     0                21  ...           844           1             0\n",
              "1      8     0                 0  ...           634           1             1\n",
              "2      8     0                10  ...           799           1             1\n",
              "3      8     0                 8  ...           891           1             1\n",
              "4      8     0                17  ...           775           1             1\n",
              "\n",
              "[5 rows x 96 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBTJBmBrssum",
        "colab_type": "code",
        "outputId": "b10a32a2-6c7d-44dc-e158-609cd6ffe0be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# set seed\n",
        "np.random.seed(123)\n",
        "\n",
        "# split data into X and y\n",
        "X = condata.loc[:, condata.columns != \"Kauf\"]\n",
        "y = condata[\"Kauf\"]\n",
        "\n",
        "# standardize the features in the dataset\n",
        "col_names = X.columns\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X, columns = col_names)\n",
        "\n",
        "# split data into training, validation and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 0)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(30809, 95) (30809,) (10270, 95) (10270,) (10270, 95) (10270,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIhDWx0BQjmf",
        "colab_type": "text"
      },
      "source": [
        "#### As shown, after splitting, we get 60% training data, 20% validation and 20% test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhxd_s8FB5h1",
        "colab_type": "text"
      },
      "source": [
        "## 2. Grid Search for Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpZ0vOH4uUIw",
        "colab_type": "code",
        "outputId": "250d68bf-c0ec-4d7c-b905-d9ab16a7cb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Using Keras for modelling\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Input, Layer, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.objectives import binary_crossentropy\n",
        "from keras import objectives, optimizers\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e_qxuL-MB3Mj",
        "colab": {}
      },
      "source": [
        "# built the model \n",
        "def nn_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(128,\n",
        "                  activation='relu', \n",
        "                  kernel_regularizer=l2(0.01),\n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_initializer=keras.initializers.he_normal(seed = 42),\n",
        "                  input_dim = 95)) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(256, \n",
        "                  activation='relu', \n",
        "                  kernel_regularizer=l2(0.01), \n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_initializer=keras.initializers.he_normal(seed = 42)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(256, \n",
        "                  activation='relu', \n",
        "                  kernel_regularizer=l2(0.01), \n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_initializer=keras.initializers.he_normal(seed = 42)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(128, \n",
        "                 activation='relu', \n",
        "                 kernel_regularizer=l2(0.01), \n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_initializer=keras.initializers.he_normal(seed=42)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(1, \n",
        "                 activation='sigmoid',\n",
        "                 kernel_regularizer=l2(0.01), \n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_initializer=keras.initializers.glorot_normal(seed=42))) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('sigmoid')) \n",
        "  \n",
        "  model.compile(optimizer=Adam(lr=0.0001),\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLsPkKwECJTi",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=nn_model, verbose=0, epochs=100) # since early stopping is implemented, we choose a larger number of epochs to ensure sufficient implementation before early stopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9b5be3e8-901e-4ab6-d60e-cce384a4dd5d",
        "id": "f1zvBZvDCJTp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# define the batch size parameter for grid search\n",
        "batch_size = [32, 64, 128]\n",
        "param_grid = dict(batch_size=batch_size)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='roc_auc', cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cc1e1159-5083-4567-ae70-252cc87c229a",
        "id": "xJrAq4K_CJTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.719251 using {'batch_size': 32}\n",
            "0.719251 (0.002308) with: {'batch_size': 32}\n",
            "0.709477 (0.001374) with: {'batch_size': 64}\n",
            "0.708092 (0.009399) with: {'batch_size': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx7SCkdZQP5f",
        "colab_type": "code",
        "outputId": "9b5be3e8-901e-4ab6-d60e-cce384a4dd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# define the batch size parameters for grid search\n",
        "batch_size = [32, 64, 128]\n",
        "param_grid = dict(batch_size=batch_size)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='roc_auc', cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB7T7z0HV7_a",
        "colab_type": "code",
        "outputId": "cc1e1159-5083-4567-ae70-252cc87c229a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.719251 using {'batch_size': 32}\n",
            "0.719251 (0.002308) with: {'batch_size': 32}\n",
            "0.709477 (0.001374) with: {'batch_size': 64}\n",
            "0.708092 (0.009399) with: {'batch_size': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwHDNxK2rGaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, built the model for learning rate grid search\n",
        "def nn_opt(lr=1e-4):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(128,\n",
        "                  activation='relu', \n",
        "                  kernel_regularizer=l2(0.01),\n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_initializer=keras.initializers.he_normal(seed = 42),\n",
        "                  input_dim = 95)) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(256, \n",
        "                  activation='relu', \n",
        "                  kernel_regularizer=l2(0.01), \n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_initializer=keras.initializers.he_normal(seed = 42)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(256, \n",
        "                  activation='relu', \n",
        "                  kernel_regularizer=l2(0.01), \n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_initializer=keras.initializers.he_normal(seed = 42)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(128, \n",
        "                 activation='relu', \n",
        "                 kernel_regularizer=l2(0.01), \n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_initializer=keras.initializers.he_normal(seed=42)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(1, \n",
        "                 activation='sigmoid',\n",
        "                 kernel_regularizer=l2(0.01), \n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_initializer=keras.initializers.glorot_normal(seed=42))) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('sigmoid'))\n",
        "  \n",
        "  model.compile(optimizer=Adam(lr=lr),\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "losuzfTcWPPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KerasClassifier(build_fn=nn_opt, verbose=0, epochs=100, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcTpBH5prR5x",
        "colab_type": "code",
        "outputId": "57561a81-8745-4cd4-ce6f-6c490491a4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# define the learning rate parameters\n",
        "lr = [0.0001, 0.0003, 0.0005, 0.0007]\n",
        "param_grid = dict(lr=lr)\n",
        "grid2 = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='roc_auc', cv=3)\n",
        "grid_result2 = grid.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d30f7d7582ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_result2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJGDK5MUjtJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXr8ckF6I8lq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Modelling and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyN7qp-hHZXY",
        "colab_type": "code",
        "outputId": "5d37c94e-0540-49d2-e2e3-909de8dc58ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128,\n",
        "                activation='relu', \n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_initializer='zeros',\n",
        "                kernel_initializer=keras.initializers.he_normal(seed = 42),\n",
        "                input_dim = 95)) # input dimension is set to 95, as we have 95 features.\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, \n",
        "                activation='relu', \n",
        "                kernel_regularizer=l2(0.01), \n",
        "                bias_initializer='zeros',\n",
        "                kernel_initializer=keras.initializers.he_normal(seed = 42)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, \n",
        "                activation='relu', \n",
        "                kernel_regularizer=l2(0.01), \n",
        "                bias_initializer='zeros',\n",
        "                kernel_initializer=keras.initializers.he_normal(seed=42)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, \n",
        "                activation='sigmoid',\n",
        "                kernel_regularizer=l2(0.01), \n",
        "                bias_initializer='zeros',\n",
        "                kernel_initializer=keras.initializers.glorot_normal(seed=42))) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('sigmoid')) # since we are dealing with binary classification, sigmoid is chosen as the activation function in the output layer.\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               12288     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 80,389\n",
            "Trainable params: 79,363\n",
            "Non-trainable params: 1,026\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO5OhYktWI17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with Adam optimizer with searched learning rate\n",
        "model.compile(optimizer=Adam(0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUbPvtm1Wy4U",
        "colab_type": "code",
        "outputId": "378214f9-f17f-4b2c-8d49-bd5ced9f4853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Fit the model using searched batch size\n",
        "cb = EarlyStopping(monitor='val_loss', \n",
        "                   mode='min', \n",
        "                   verbose=0, \n",
        "                   patience=8,\n",
        "                   restore_best_weights=True)\n",
        "\n",
        "model.fit(x=X_train, \n",
        "          y=y_train,\n",
        "          validation_data=[X_val, y_val],\n",
        "          epochs=100, \n",
        "          batch_size=32,\n",
        "          callbacks=[cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 30809 samples, validate on 10270 samples\n",
            "Epoch 1/100\n",
            " 6176/30809 [=====>........................] - ETA: 1:43 - loss: 10.2326 - acc: 0.5102"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc_AktsEzw8-",
        "colab_type": "text"
      },
      "source": [
        "## 4. Predicting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkPv7zvIrnMc",
        "colab_type": "text"
      },
      "source": [
        "#### Since the dataset is imbalanced, instead of using accuracy, we will apply AUC score as the evaluation measure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0nO2NXtalKd",
        "colab_type": "code",
        "outputId": "c2c101cf-7cc7-4d27-ae5a-7ee06fa09be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Make predictions\n",
        "pred_val = model.predict(X_val)\n",
        "pred = model.predict(X_test)\n",
        "print('AUC in the val. set: ', metrics.roc_auc_score(y_val, pred_val))\n",
        "print('AUC in the test set: ', metrics.roc_auc_score(y_test, pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC in the val. set:  0.7326838265000172\n",
            "AUC in the test set:  0.731873837052737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvpSdTp8a5DE",
        "colab_type": "code",
        "outputId": "db32d303-09c4-465d-8018-6e812910278c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "pred_val = model.predict(X_val)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "def show_AUC(y_test, pred):\n",
        "  false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n",
        "  roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "\n",
        "  plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
        "  label='AUC = %0.2f'% roc_auc)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.plot([0,1],[0,1],'r--')\n",
        "  plt.xlim([-0.1,1.2])\n",
        "  plt.ylim([-0.1,1.2])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "print('AUC in the val. set: ', metrics.roc_auc_score(y_val, pred_val))\n",
        "print('AUC in the test set: ', metrics.roc_auc_score(y_test, pred))\n",
        "show_AUC(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC in the val. set:  0.7326838265000172\n",
            "AUC in the test set:  0.731873837052737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO0w6nRaD2Pt",
        "colab_type": "text"
      },
      "source": [
        "#### As a result, we get a AUC score of 0.74. For further improvement, it would be helpful if we implement grid search for more hyperparameters, such as optimizers, dropout rate and momentum. In addition, random search for hyperparameter optimization and the comparison between both methods are also worth trying."
      ]
    }
  ]
}